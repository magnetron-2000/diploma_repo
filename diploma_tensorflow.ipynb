{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f04fbf-b900-48bd-a2c1-6ea2895b26af",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6553d77d-0de9-4d79-bede-db30eb32a546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:30:02.740922: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 11:30:02.782723: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 11:30:02.783376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 11:30:03.511855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6865a-b923-4561-a319-242ed82b2ab4",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51392f27-7832-4cab-a3ea-0a7c755446af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_BEST_ACCURACY_RESULTS = []\n",
    "SAVED_MODEL_BEST_LOSS_RESULTS = []\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb70308-5f4f-4e97-a783-ddce4318c798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data = utils.load_img(data, color_mode='grayscale', target_size=(64, 64))\n",
    "    data = utils.img_to_array(data)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    data = data / 255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3393a6-e4e3-4d4d-9f97-6b82aa56a007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_examples_and_classes(dataset_dir, num):\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    examples = []\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        examples.append(os.path.join(class_dir, images[num]))\n",
    "\n",
    "    return classes, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa81b474-0966-492b-8f25-eba67ab5cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(accuracy, loss, val_accuracy, val_loss):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('epoch')\n",
    "\n",
    "    ax1.set_ylabel('total loss')\n",
    "    ax1.plot(loss,color='tab:red')\n",
    "    ax1.plot( val_loss, color='tab:brown')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('accuracy')  \n",
    "    ax2.plot( accuracy, color='tab:blue')\n",
    "    ax2.plot( val_accuracy, color='tab:green')\n",
    "    ax2.tick_params(axis='y')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71d1655-70cd-419b-b7cb-eff7a5a542c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_many(title='title', data=[]):\n",
    "    for i,o in enumerate(data):\n",
    "        plt.figure(i)\n",
    "        plt.plot([i for i in range(EPOCHS)],o, label=title)\n",
    "        plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab19927f-1208-4bfd-a329-933b6a21a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_or_min_avarage_val(list_of_data, accuracy=True):\n",
    "    dict_all_l = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        dict_all_l[i] = sum(o)/len(o)\n",
    "    if accuracy:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1], reverse=True))\n",
    "    else:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253f7b60-36bb-494f-9a81-078cc84b280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lists():\n",
    "    t = time.ctime(time.time())[:-5]\n",
    "    with open(f'accuracy {t}.txt', 'w') as f:\n",
    "        for item in SAVED_MODEL_BEST_ACCURACY_RESULTS:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    # with open(f'loss {t}.txt', 'w') as f:\n",
    "    #     for item in SAVED_MODEL_BEST_LOSS_RESULTS:\n",
    "    #         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d59b4e0-8d86-4f58-a171-392fe5498f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filename):\n",
    "    lst = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            if line in ('', ' ','\\n'):\n",
    "                break\n",
    "            line = line[1:-2].split(', ')\n",
    "            lst.append([float(i.strip()) for i in line])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9c0e79-cdeb-4c1a-9cfb-ec1fcd518589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_best_res(list_of_data):\n",
    "    max_val = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        max_val[i] = max(o)\n",
    "    return dict(sorted(max_val.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198520c-7008-4b6c-b7dd-bc94f7fc2f08",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7138b14b-26ee-4297-9c9b-2c552d9d6c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22734 images belonging to 164 classes.\n",
      "Found 5682 images belonging to 164 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_folder = \"/home/jovyan/dataset/dataset2/train\"\n",
    "test_folder = \"/home/jovyan/dataset/dataset2/test\"\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_folder,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder,\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f1f8-a05a-47b6-8962-711522d51998",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e2d5c7a-7d38-463b-ac3e-19033eaef6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_32 (Conv2D)          (None, 63, 63, 8)         40        \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 31, 31, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_32 (Bat  (None, 31, 31, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 31, 31, 8)         264       \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 15, 15, 8)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 15, 15, 8)        32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 15, 15, 8)         264       \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 7, 7, 8)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 7, 7, 8)          32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 7, 7, 8)           264       \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 7, 7, 8)          32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 392)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 512)               201216    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 164)               84132     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 286,308\n",
      "Trainable params: 286,244\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model(in_1=8, in_2=8, in_3=8, in_4=8):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=in_1,kernel_size=2, strides=(1,1), input_shape=(64,64,1), padding='valid', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=in_2,kernel_size=2, strides=1, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=in_3,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=in_4,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 512 , activation = 'tanh'))\n",
    "    model.add(Dense(units = 164 , activation = 'softmax'))\n",
    "\n",
    "    model.compile( optimizer = 'Adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "summary_example = model()\n",
    "summary_example.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf6c4-bed3-4b6f-92bd-9a2e9c16403a",
   "metadata": {},
   "source": [
    "choose best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820b32f0-c987-41b1-bf6a-f268b1675ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_and_best_hyperparameters():\n",
    "    nums = [ 8,16, 32, 64]\n",
    "    start_time1 = time.time()\n",
    "    for i in nums:        \n",
    "        start_time2 = time.time()\n",
    "        \n",
    "        ready_model = model(i,i*2,i*3, i*4)        \n",
    "        trained_model = ready_model.fit(training_set, steps_per_epoch = 32, epochs = EPOCHS, validation_data = test_set)\n",
    "        \n",
    "        end_time2 = time.time()\n",
    "        print(\"for one training time taken: {:.2f} seconds\".format(end_time2 - start_time2))\n",
    "        \n",
    "        accuracy = trained_model.history['accuracy']\n",
    "        loss = trained_model.history['loss']\n",
    "\n",
    "        SAVED_MODEL_BEST_ACCURACY_RESULTS.append(accuracy)\n",
    "        SAVED_MODEL_BEST_LOSS_RESULTS.append(loss)\n",
    "        \n",
    "    end_time1 = time.time()\n",
    "    print(\"for all training time taken: {:.2f} seconds\".format(end_time1 - start_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa15b49-da5a-4cbb-bf6a-0fadef1326ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:30:06.174210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.2450 - accuracy: 0.0146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:30:08.733071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 146ms/step - loss: 5.2450 - accuracy: 0.0146 - val_loss: 5.1202 - val_accuracy: 0.0070\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 5.0982 - accuracy: 0.0205 - val_loss: 5.2327 - val_accuracy: 0.0074\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 5s 148ms/step - loss: 4.9750 - accuracy: 0.0342 - val_loss: 5.3760 - val_accuracy: 0.0111\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 4.8841 - accuracy: 0.0352 - val_loss: 5.4492 - val_accuracy: 0.0102\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 4.8271 - accuracy: 0.0303 - val_loss: 5.4401 - val_accuracy: 0.0097\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 5s 156ms/step - loss: 4.7972 - accuracy: 0.0388 - val_loss: 5.5855 - val_accuracy: 0.0084\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 4s 130ms/step - loss: 4.7057 - accuracy: 0.0547 - val_loss: 5.5591 - val_accuracy: 0.0100\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.6422 - accuracy: 0.0771 - val_loss: 5.5927 - val_accuracy: 0.0095\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 4.6126 - accuracy: 0.0586 - val_loss: 5.4187 - val_accuracy: 0.0141\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 4.5750 - accuracy: 0.0596 - val_loss: 5.3829 - val_accuracy: 0.0106\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 5s 160ms/step - loss: 4.4564 - accuracy: 0.0781 - val_loss: 5.0732 - val_accuracy: 0.0273\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 5s 152ms/step - loss: 4.4573 - accuracy: 0.0732 - val_loss: 4.9912 - val_accuracy: 0.0317\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 5s 173ms/step - loss: 4.4504 - accuracy: 0.0752 - val_loss: 4.9260 - val_accuracy: 0.0400\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 5s 161ms/step - loss: 4.3847 - accuracy: 0.0781 - val_loss: 4.8948 - val_accuracy: 0.0391\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 4.3763 - accuracy: 0.0908 - val_loss: 4.8089 - val_accuracy: 0.0470\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 4.3521 - accuracy: 0.0879 - val_loss: 4.6776 - val_accuracy: 0.0697\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 4.2597 - accuracy: 0.1035 - val_loss: 4.7195 - val_accuracy: 0.0618\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 5s 151ms/step - loss: 4.2245 - accuracy: 0.1113 - val_loss: 4.6915 - val_accuracy: 0.0646\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 4.3003 - accuracy: 0.1035 - val_loss: 4.4181 - val_accuracy: 0.0957\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 4.2228 - accuracy: 0.1143 - val_loss: 4.3541 - val_accuracy: 0.0970\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 4s 129ms/step - loss: 4.2326 - accuracy: 0.1104 - val_loss: 4.5037 - val_accuracy: 0.0795\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 4.1057 - accuracy: 0.1270 - val_loss: 4.4896 - val_accuracy: 0.0832\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 4.1343 - accuracy: 0.1328 - val_loss: 4.2987 - val_accuracy: 0.1049\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 4s 133ms/step - loss: 4.0118 - accuracy: 0.1357 - val_loss: 4.3398 - val_accuracy: 0.0954\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 4s 135ms/step - loss: 4.0428 - accuracy: 0.1387 - val_loss: 4.5397 - val_accuracy: 0.0773\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 4s 136ms/step - loss: 3.9610 - accuracy: 0.1426 - val_loss: 4.6187 - val_accuracy: 0.0665\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 6s 179ms/step - loss: 3.9858 - accuracy: 0.1348 - val_loss: 4.4685 - val_accuracy: 0.0855\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 3.9836 - accuracy: 0.1523 - val_loss: 4.3713 - val_accuracy: 0.0991\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 3.8440 - accuracy: 0.1768 - val_loss: 4.6451 - val_accuracy: 0.0700\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 3.9892 - accuracy: 0.1445 - val_loss: 4.1329 - val_accuracy: 0.1223\n",
      "for one training time taken: 151.44 seconds\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:32:37.453596: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.2882 - accuracy: 0.0107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:32:41.794200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 262ms/step - loss: 5.2882 - accuracy: 0.0107 - val_loss: 5.1656 - val_accuracy: 0.0088\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 5.0920 - accuracy: 0.0205 - val_loss: 5.3905 - val_accuracy: 0.0067\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 8s 252ms/step - loss: 5.0524 - accuracy: 0.0234 - val_loss: 5.5768 - val_accuracy: 0.0088\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 4.9165 - accuracy: 0.0410 - val_loss: 5.7717 - val_accuracy: 0.0088\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 4.9132 - accuracy: 0.0303 - val_loss: 5.7008 - val_accuracy: 0.0088\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 4.7516 - accuracy: 0.0527 - val_loss: 5.6822 - val_accuracy: 0.0072\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 7s 221ms/step - loss: 4.6869 - accuracy: 0.0537 - val_loss: 5.7348 - val_accuracy: 0.0109\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 7s 214ms/step - loss: 4.5535 - accuracy: 0.0726 - val_loss: 5.7885 - val_accuracy: 0.0104\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 4.5749 - accuracy: 0.0676 - val_loss: 5.7881 - val_accuracy: 0.0097\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 4.4492 - accuracy: 0.0811 - val_loss: 5.7551 - val_accuracy: 0.0104\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 4.3896 - accuracy: 0.0918 - val_loss: 5.8206 - val_accuracy: 0.0118\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 4.3671 - accuracy: 0.0869 - val_loss: 5.4217 - val_accuracy: 0.0118\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 4.3533 - accuracy: 0.0954 - val_loss: 5.2027 - val_accuracy: 0.0190\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 5s 171ms/step - loss: 4.3031 - accuracy: 0.0918 - val_loss: 5.1676 - val_accuracy: 0.0232\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 4.2919 - accuracy: 0.1074 - val_loss: 5.0921 - val_accuracy: 0.0324\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 4.1333 - accuracy: 0.1299 - val_loss: 4.8770 - val_accuracy: 0.0507\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 4.0623 - accuracy: 0.1426 - val_loss: 4.7567 - val_accuracy: 0.0477\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 4.1058 - accuracy: 0.1230 - val_loss: 4.5908 - val_accuracy: 0.0767\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 5s 167ms/step - loss: 4.0206 - accuracy: 0.1270 - val_loss: 4.2311 - val_accuracy: 0.1051\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 4.1060 - accuracy: 0.1279 - val_loss: 4.6064 - val_accuracy: 0.0757\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 3.9242 - accuracy: 0.1631 - val_loss: 4.2172 - val_accuracy: 0.1165\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 3.8634 - accuracy: 0.1670 - val_loss: 3.9307 - val_accuracy: 0.1521\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 3.8642 - accuracy: 0.1710 - val_loss: 4.1218 - val_accuracy: 0.1306\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 3.7873 - accuracy: 0.1729 - val_loss: 4.3787 - val_accuracy: 0.1075\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 3.7182 - accuracy: 0.1875 - val_loss: 4.4015 - val_accuracy: 0.1093\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 5s 170ms/step - loss: 3.8037 - accuracy: 0.1641 - val_loss: 3.9257 - val_accuracy: 0.1535\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 5s 172ms/step - loss: 3.6862 - accuracy: 0.1836 - val_loss: 3.9101 - val_accuracy: 0.1531\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 3.6387 - accuracy: 0.1826 - val_loss: 4.6081 - val_accuracy: 0.1019\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 3.6842 - accuracy: 0.1729 - val_loss: 5.9662 - val_accuracy: 0.0313\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 5s 169ms/step - loss: 3.6407 - accuracy: 0.1895 - val_loss: 5.3349 - val_accuracy: 0.0530\n",
      "for one training time taken: 176.57 seconds\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:35:33.988610: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.4059 - accuracy: 0.0127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:35:38.517611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 287ms/step - loss: 5.4059 - accuracy: 0.0127 - val_loss: 5.2586 - val_accuracy: 0.0106\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 9s 289ms/step - loss: 5.3144 - accuracy: 0.0186 - val_loss: 5.4899 - val_accuracy: 0.0106\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 9s 291ms/step - loss: 5.1386 - accuracy: 0.0244 - val_loss: 5.7522 - val_accuracy: 0.0049\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 5.0681 - accuracy: 0.0273 - val_loss: 6.0871 - val_accuracy: 0.0044\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 5.0287 - accuracy: 0.0332 - val_loss: 5.8383 - val_accuracy: 0.0088\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 5.0128 - accuracy: 0.0264 - val_loss: 5.8395 - val_accuracy: 0.0062\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 9s 282ms/step - loss: 4.9379 - accuracy: 0.0361 - val_loss: 5.8533 - val_accuracy: 0.0088\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 9s 281ms/step - loss: 4.7852 - accuracy: 0.0439 - val_loss: 5.9612 - val_accuracy: 0.0049\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 10s 330ms/step - loss: 4.6680 - accuracy: 0.0537 - val_loss: 5.6753 - val_accuracy: 0.0090\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 11s 345ms/step - loss: 4.6222 - accuracy: 0.0596 - val_loss: 5.8835 - val_accuracy: 0.0104\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 10s 303ms/step - loss: 4.5673 - accuracy: 0.0811 - val_loss: 5.6708 - val_accuracy: 0.0092\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 9s 292ms/step - loss: 4.6194 - accuracy: 0.0732 - val_loss: 5.5752 - val_accuracy: 0.0139\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 10s 321ms/step - loss: 4.4791 - accuracy: 0.0703 - val_loss: 5.8439 - val_accuracy: 0.0095\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 10s 330ms/step - loss: 4.4732 - accuracy: 0.0762 - val_loss: 5.3904 - val_accuracy: 0.0232\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 9s 287ms/step - loss: 4.3664 - accuracy: 0.0928 - val_loss: 5.2948 - val_accuracy: 0.0248\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 10s 302ms/step - loss: 4.3736 - accuracy: 0.0938 - val_loss: 5.3198 - val_accuracy: 0.0236\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 10s 305ms/step - loss: 4.2832 - accuracy: 0.1094 - val_loss: 4.7054 - val_accuracy: 0.0567\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 10s 332ms/step - loss: 4.1578 - accuracy: 0.1162 - val_loss: 4.6178 - val_accuracy: 0.0620\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 10s 307ms/step - loss: 4.1846 - accuracy: 0.1309 - val_loss: 4.7095 - val_accuracy: 0.0614\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 10s 313ms/step - loss: 4.1991 - accuracy: 0.1230 - val_loss: 4.3137 - val_accuracy: 0.1031\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 10s 310ms/step - loss: 4.0791 - accuracy: 0.1514 - val_loss: 4.3137 - val_accuracy: 0.1007\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 10s 314ms/step - loss: 4.1085 - accuracy: 0.1182 - val_loss: 4.5693 - val_accuracy: 0.0808\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 9s 287ms/step - loss: 3.9299 - accuracy: 0.1582 - val_loss: 4.1110 - val_accuracy: 0.1160\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 9s 298ms/step - loss: 3.9426 - accuracy: 0.1523 - val_loss: 4.8127 - val_accuracy: 0.0669\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 11s 343ms/step - loss: 3.8869 - accuracy: 0.1670 - val_loss: 4.4858 - val_accuracy: 0.0901\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 11s 343ms/step - loss: 3.8760 - accuracy: 0.1572 - val_loss: 4.6902 - val_accuracy: 0.0817\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 14s 459ms/step - loss: 3.8815 - accuracy: 0.1758 - val_loss: 4.7794 - val_accuracy: 0.0692\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 15s 463ms/step - loss: 3.7125 - accuracy: 0.1816 - val_loss: 4.9360 - val_accuracy: 0.0583\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 3.5400 - accuracy: 0.2197 - val_loss: 4.4452 - val_accuracy: 0.0935\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 3.6090 - accuracy: 0.2217 - val_loss: 3.9296 - val_accuracy: 0.1434\n",
      "for one training time taken: 307.47 seconds\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:40:41.489291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.5751 - accuracy: 0.0088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 11:40:54.320478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 34s 1s/step - loss: 5.5751 - accuracy: 0.0088 - val_loss: 5.3447 - val_accuracy: 0.0060\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 43s 1s/step - loss: 5.3901 - accuracy: 0.0176 - val_loss: 5.6951 - val_accuracy: 0.0076\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 49s 2s/step - loss: 5.2770 - accuracy: 0.0176 - val_loss: 5.7805 - val_accuracy: 0.0072\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 50s 2s/step - loss: 5.2225 - accuracy: 0.0137 - val_loss: 5.9405 - val_accuracy: 0.0077\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 50s 2s/step - loss: 5.1630 - accuracy: 0.0303 - val_loss: 5.8553 - val_accuracy: 0.0074\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 52s 2s/step - loss: 5.1594 - accuracy: 0.0303 - val_loss: 6.0634 - val_accuracy: 0.0072\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 24s 741ms/step - loss: 5.1246 - accuracy: 0.0234 - val_loss: 6.1121 - val_accuracy: 0.0100\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 22s 699ms/step - loss: 5.0903 - accuracy: 0.0273 - val_loss: 5.7571 - val_accuracy: 0.0056\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 22s 704ms/step - loss: 5.0727 - accuracy: 0.0342 - val_loss: 5.7043 - val_accuracy: 0.0088\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 22s 706ms/step - loss: 5.0722 - accuracy: 0.0195 - val_loss: 5.7362 - val_accuracy: 0.0044\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 22s 699ms/step - loss: 4.9920 - accuracy: 0.0283 - val_loss: 5.6440 - val_accuracy: 0.0070\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 22s 693ms/step - loss: 4.9536 - accuracy: 0.0322 - val_loss: 5.4676 - val_accuracy: 0.0118\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 22s 694ms/step - loss: 4.9097 - accuracy: 0.0398 - val_loss: 5.6104 - val_accuracy: 0.0109\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 22s 693ms/step - loss: 4.8210 - accuracy: 0.0371 - val_loss: 5.3375 - val_accuracy: 0.0164\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 22s 699ms/step - loss: 4.8386 - accuracy: 0.0439 - val_loss: 5.0440 - val_accuracy: 0.0308\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 4.7997 - accuracy: 0.0498 - val_loss: 5.2687 - val_accuracy: 0.0172\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 22s 697ms/step - loss: 4.7508 - accuracy: 0.0477 - val_loss: 5.2919 - val_accuracy: 0.0144\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 22s 706ms/step - loss: 4.6865 - accuracy: 0.0586 - val_loss: 5.4503 - val_accuracy: 0.0236\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 4.6590 - accuracy: 0.0684 - val_loss: 4.9540 - val_accuracy: 0.0340\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 22s 710ms/step - loss: 4.6065 - accuracy: 0.0684 - val_loss: 5.1283 - val_accuracy: 0.0348\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 22s 707ms/step - loss: 4.5857 - accuracy: 0.0693 - val_loss: 5.2831 - val_accuracy: 0.0340\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 22s 695ms/step - loss: 4.4442 - accuracy: 0.0752 - val_loss: 4.9801 - val_accuracy: 0.0389\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 22s 709ms/step - loss: 4.4939 - accuracy: 0.0869 - val_loss: 5.1373 - val_accuracy: 0.0454\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 22s 694ms/step - loss: 4.4596 - accuracy: 0.0840 - val_loss: 4.7133 - val_accuracy: 0.0595\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 22s 702ms/step - loss: 4.4396 - accuracy: 0.0967 - val_loss: 4.6121 - val_accuracy: 0.0720\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 22s 706ms/step - loss: 4.3565 - accuracy: 0.0908 - val_loss: 4.3817 - val_accuracy: 0.0855\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 22s 700ms/step - loss: 4.3394 - accuracy: 0.0889 - val_loss: 4.7484 - val_accuracy: 0.0509\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 22s 709ms/step - loss: 4.2424 - accuracy: 0.1045 - val_loss: 4.4864 - val_accuracy: 0.0755\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 22s 697ms/step - loss: 4.2427 - accuracy: 0.0967 - val_loss: 4.4481 - val_accuracy: 0.0898\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 22s 704ms/step - loss: 4.2384 - accuracy: 0.1191 - val_loss: 4.7779 - val_accuracy: 0.0537\n",
      "for one training time taken: 808.87 seconds\n",
      "for all training time taken: 1444.34 seconds\n"
     ]
    }
   ],
   "source": [
    "model_and_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e05ca7b-7539-48ec-92a6-7a7f88d8a982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted list of average  epochs' values for accuracy   {1: 0.11104551057020823, 2: 0.1001953125, 0: 0.09116854866345724, 3: 0.05363198419411977}\n",
      "sorted list of max  epochs' values for accuracy   {2: 0.2216796875, 1: 0.189453125, 0: 0.1767578125, 3: 0.119140625}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted list of average  epochs' values for accuracy  \", max_or_min_avarage_val(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "save_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67179992-f15d-432b-8e32-45e179ce34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'accuracy Sat May  6 11:19:23.txt'\n",
    "# l = read_list_from_file(file)\n",
    "# print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b49b6d-64b7-4aa9-b92e-f71dfeeb6f00",
   "metadata": {},
   "source": [
    "train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a3702-1baf-4dab-a09c-3dee963376fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    ready_model = model(8,16,64)\n",
    "    call_back = ModelCheckpoint(f\"/home/jovyan/weights.hdf5\", monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    trained_model = model.fit(training_set, steps_per_epoch = 32, epochs = 30, validation_data = test_set, callbacks = [call_back])\n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d089bf-cdf6-466c-b982-050830bc5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd227c-d4d8-4b5d-80fe-3f7959fa5aa4",
   "metadata": {},
   "source": [
    "plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3b27-a90b-455a-93cb-59328ed8fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_many('accuracy', SAVED_MODEL_BEST_ACCURACY_RESULTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a59931-66c2-4806-a777-e4bfee1cad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if trained_model:\n",
    "    plot(trained_model.history['accuracy'], trained_model.history['loss'], trained_model.history['val_accuracy'], trained_model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8f3f1-649e-452d-922b-fa70c8ce7d92",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc123d2-9d89-44f2-989e-5d4c4d4bedc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_model = Sequential()\n",
    "for layer in model.layers[:-1]:\n",
    "    predict_model.add(layer)\n",
    "predict_model.add(Dense(units=1, activation=None))\n",
    "predict_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "predict_model.summary()\n",
    "\n",
    "\n",
    "predict_model.load_weights('weights.hdf5', skip_mismatch=True, by_name=True)\n",
    "\n",
    "# # Load weights and biases from model manually\n",
    "# for i in range(len(predict_model.layers) - 1):\n",
    "#     predict_model.layers[i].set_weights(model.layers[i].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0dd9f-d192-4a8a-83a3-a97d19effe0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, known_data_path, unknown_data_path):\n",
    "    known_data = transform(known_data_path)\n",
    "    unknown_data = transform(unknown_data_path)\n",
    "\n",
    "    known_data = model.predict(known_data)\n",
    "    unknown_data = model.predict(unknown_data)\n",
    "    distance = unknown_data - known_data\n",
    "\n",
    "    threshold = 0.018614814\n",
    "    return  distance[0][0] > threshold, distance[0][0]\n",
    "\n",
    "predict(predict_model, '/home/jovyan/11.jpg', '/home/jovyan/21.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed7301-057b-4f6a-9569-c220b9e72a18",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9c60-bc0c-4586-8fc2-4eb86d972c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes, examples1 = get_examples_and_classes(test_folder,1)\n",
    "classes, examples2 = get_examples_and_classes(test_folder,2)\n",
    "y_true = [i for i in range(len(classes))]\n",
    "y_predict_tensors = []\n",
    "y_predict_labels = []\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    predict_label, predict_tensor = predict(predict_model, examples1[i], examples2[i])\n",
    "    y_predict_tensors.append(predict_tensor)\n",
    "    y_predict_labels.append(predict_label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292a756-9bbe-4a08-8a58-9d30b170abb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_predict_labels, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71eed0-463d-4c6b-9b8e-baf435aa25ce",
   "metadata": {},
   "source": [
    "choose best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094515cc-bc73-4f5c-8a6b-195dc45eadd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.0001, 0.5, 1000)\n",
    "\n",
    "# Calculate F1 score for each threshold\n",
    "f1_scores = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_predict_tensors < threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "# Choose the threshold that maximizes F1 score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
