{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f04fbf-b900-48bd-a2c1-6ea2895b26af",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6553d77d-0de9-4d79-bede-db30eb32a546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:05:55.182913: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 11:05:55.659073: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-09 11:05:55.662988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-09 11:05:56.993398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6865a-b923-4561-a319-242ed82b2ab4",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51392f27-7832-4cab-a3ea-0a7c755446af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_BEST_ACCURACY_RESULTS = []\n",
    "SAVED_MODEL_BEST_LOSS_RESULTS = []\n",
    "IMG_SIZE = 64\n",
    "EPOCHS = 90 # try different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb70308-5f4f-4e97-a783-ddce4318c798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_and_transform(path):\n",
    "    data = utils.load_img(path, color_mode='grayscale', target_size=(64, 64))\n",
    "    data = utils.img_to_array(data)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    data = data / 255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f1fcef-0994-4627-b40f-3acdbdddfdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(dataset_dir): # build 2 datasets for training and testing\n",
    "    x_train, y_train = [], []\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        for image in images:\n",
    "            full_image_path = os.path.join(class_dir, image)\n",
    "            if 'ipynb_checkpoints' in full_image_path:\n",
    "                continue\n",
    "            x_train.append(get_image_and_transform(full_image_path))\n",
    "            y_train.append(i)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad3393a6-e4e3-4d4d-9f97-6b82aa56a007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_examples_and_classes(dataset_dir, num): # return persons' names and persons' ears\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    examples = []\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        examples.append(os.path.join(class_dir, images[num]))\n",
    "\n",
    "    return classes, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa81b474-0966-492b-8f25-eba67ab5cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(accuracy, loss, val_accuracy, val_loss): # return schedule of accuracy and loss\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('epoch')\n",
    "\n",
    "    ax1.set_ylabel('total loss')\n",
    "    ax1.plot(loss,color='tab:red')\n",
    "    ax1.plot( val_loss, color='tab:brown')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('accuracy')  \n",
    "    ax2.plot( accuracy, color='tab:blue')\n",
    "    ax2.plot( val_accuracy, color='tab:green')\n",
    "    ax2.tick_params(axis='y')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71d1655-70cd-419b-b7cb-eff7a5a542c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_many(title='title', data=[]): # return schedules of accuracy\n",
    "    for i,o in enumerate(data):\n",
    "        plt.figure(i)\n",
    "        plt.plot([i for i in range(EPOCHS)],o, label=title)\n",
    "        plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab19927f-1208-4bfd-a329-933b6a21a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_or_min_avarage_val(list_of_data, accuracy=True): #return dictionary of average values of lists\n",
    "    dict_all_l = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        dict_all_l[i] = sum(o)/len(o)\n",
    "    if accuracy:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1], reverse=True))\n",
    "    else:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "253f7b60-36bb-494f-9a81-078cc84b280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lists(): # save lists of accuracy and loss\n",
    "    t = time.ctime(time.time())[:-5]\n",
    "    with open(f'accuracy {t}.txt', 'w') as f:\n",
    "        for item in SAVED_MODEL_BEST_ACCURACY_RESULTS:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    # with open(f'loss {t}.txt', 'w') as f:\n",
    "    #     for item in SAVED_MODEL_BEST_LOSS_RESULTS:\n",
    "    #         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d59b4e0-8d86-4f58-a171-392fe5498f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filename): # read accuracy and loss data  from files\n",
    "    lst = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            if line in ('', ' ','\\n'):\n",
    "                break\n",
    "            line = line[1:-2].split(', ')\n",
    "            lst.append([float(i.strip()) for i in line])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d9c0e79-cdeb-4c1a-9cfb-ec1fcd518589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_best_res(list_of_data): # return max value in every list of accuracy\n",
    "    max_val = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        max_val[i] = max(o)\n",
    "    return dict(sorted(max_val.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198520c-7008-4b6c-b7dd-bc94f7fc2f08",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ed47a4-8c69-48d5-af81-e6d5f87955d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folder = \"/home/jovyan/dataset/dataset2/train\"\n",
    "test_folder = \"/home/jovyan/dataset/dataset2/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7138b14b-26ee-4297-9c9b-2c552d9d6c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22736 images belonging to 164 classes.\n",
      "Found 5683 images belonging to 164 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator()#rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator()#rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_folder,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder,\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            color_mode='grayscale')\n",
    "\n",
    "# print(training_set.filepaths)\n",
    "# print(training_set.classes)\n",
    "# print(training_set.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f1f8-a05a-47b6-8962-711522d51998",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e2d5c7a-7d38-463b-ac3e-19033eaef6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 8)        32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 8)         264       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 8)           264       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               66048     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 164)               84132     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 151,500\n",
      "Trainable params: 151,436\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model(in_1=8, in_2=8, in_3=8, in_4=8):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=in_1,kernel_size=3, strides=(1,1), input_shape=(64,64,1), padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=in_2,kernel_size=3, strides=1, padding = 'same', activation = 'relu')) # try elu\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=in_3,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=in_4,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(Dense(units = 512 , activation = 'tanh')) # try delete\n",
    "    # model.add(Dense(units = 1))\n",
    "    model.add(Dense(units = 164 , activation = 'softmax'))\n",
    "\n",
    "    model.compile( optimizer='Adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "summary_example = model()\n",
    "summary_example.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf6c4-bed3-4b6f-92bd-9a2e9c16403a",
   "metadata": {},
   "source": [
    "choose best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "820b32f0-c987-41b1-bf6a-f268b1675ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_and_best_hyperparameters(nums):\n",
    "    start_time1 = time.time() \n",
    "    for i in nums:\n",
    "        start_time2 = time.time()\n",
    "        \n",
    "        ready_model = model(i,i*2,i*3, i*4)        # change order \n",
    "        trained_model = ready_model.fit(training_set, steps_per_epoch = 32, epochs = EPOCHS, validation_data = test_set)\n",
    "        \n",
    "        print(\"for one training time taken: {:.2f} seconds\".format(time.time() - start_time2)) # how much time one training take\n",
    "        \n",
    "        accuracy = trained_model.history['accuracy']\n",
    "        loss = trained_model.history['loss']\n",
    "\n",
    "        SAVED_MODEL_BEST_ACCURACY_RESULTS.append(accuracy)\n",
    "        SAVED_MODEL_BEST_LOSS_RESULTS.append(loss)\n",
    "        \n",
    "    print(\"for all training time taken: {:.2f} seconds\".format(time.time() - start_time1)) # how much time all training take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaa15b49-da5a-4cbb-bf6a-0fadef1326ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:27:58.408382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.3692 - accuracy: 0.0156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:28:01.801908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 9s 238ms/step - loss: 5.3692 - accuracy: 0.0156 - val_loss: 5.9510 - val_accuracy: 0.0051\n",
      "Epoch 2/70\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 5.1378 - accuracy: 0.0352 - val_loss: 5.4514 - val_accuracy: 0.0125\n",
      "Epoch 3/70\n",
      "32/32 [==============================] - 8s 260ms/step - loss: 5.0861 - accuracy: 0.0322 - val_loss: 5.1169 - val_accuracy: 0.0201\n",
      "Epoch 4/70\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 4.9231 - accuracy: 0.0342 - val_loss: 5.0729 - val_accuracy: 0.0241\n",
      "Epoch 5/70\n",
      "32/32 [==============================] - 7s 236ms/step - loss: 4.8446 - accuracy: 0.0498 - val_loss: 4.8870 - val_accuracy: 0.0338\n",
      "Epoch 6/70\n",
      "32/32 [==============================] - 10s 305ms/step - loss: 4.7662 - accuracy: 0.0498 - val_loss: 4.8554 - val_accuracy: 0.0401\n",
      "Epoch 7/70\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 4.6682 - accuracy: 0.0684 - val_loss: 4.7450 - val_accuracy: 0.0480\n",
      "Epoch 8/70\n",
      "32/32 [==============================] - 10s 306ms/step - loss: 4.5678 - accuracy: 0.0791 - val_loss: 4.7055 - val_accuracy: 0.0528\n",
      "Epoch 9/70\n",
      "32/32 [==============================] - 9s 301ms/step - loss: 4.4444 - accuracy: 0.0938 - val_loss: 4.7223 - val_accuracy: 0.0501\n",
      "Epoch 10/70\n",
      "32/32 [==============================] - 9s 287ms/step - loss: 4.3944 - accuracy: 0.0996 - val_loss: 4.6127 - val_accuracy: 0.0614\n",
      "Epoch 11/70\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 4.2195 - accuracy: 0.1270 - val_loss: 4.4332 - val_accuracy: 0.0853\n",
      "Epoch 12/70\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 4.1695 - accuracy: 0.1211 - val_loss: 4.4386 - val_accuracy: 0.0787\n",
      "Epoch 13/70\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 4.1134 - accuracy: 0.1455 - val_loss: 4.5297 - val_accuracy: 0.0741\n",
      "Epoch 14/70\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 4.1108 - accuracy: 0.1260 - val_loss: 4.8514 - val_accuracy: 0.0581\n",
      "Epoch 15/70\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 3.8452 - accuracy: 0.1738 - val_loss: 4.9446 - val_accuracy: 0.0572\n",
      "Epoch 16/70\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 3.9156 - accuracy: 0.1523 - val_loss: 4.8823 - val_accuracy: 0.0563\n",
      "Epoch 17/70\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 3.7780 - accuracy: 0.1875 - val_loss: 4.3991 - val_accuracy: 0.0948\n",
      "Epoch 18/70\n",
      "32/32 [==============================] - 6s 206ms/step - loss: 3.7394 - accuracy: 0.1709 - val_loss: 4.5844 - val_accuracy: 0.0824\n",
      "Epoch 19/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 3.6881 - accuracy: 0.2061 - val_loss: 4.0960 - val_accuracy: 0.1307\n",
      "Epoch 20/70\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 3.5718 - accuracy: 0.2207 - val_loss: 4.1763 - val_accuracy: 0.1260\n",
      "Epoch 21/70\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.5291 - accuracy: 0.2344 - val_loss: 4.2216 - val_accuracy: 0.1228\n",
      "Epoch 22/70\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 3.4075 - accuracy: 0.2305 - val_loss: 4.0825 - val_accuracy: 0.1343\n",
      "Epoch 23/70\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 3.2510 - accuracy: 0.2803 - val_loss: 4.1813 - val_accuracy: 0.1270\n",
      "Epoch 24/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 3.2675 - accuracy: 0.2676 - val_loss: 3.8434 - val_accuracy: 0.1675\n",
      "Epoch 25/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 3.1951 - accuracy: 0.2871 - val_loss: 3.9159 - val_accuracy: 0.1605\n",
      "Epoch 26/70\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 3.1599 - accuracy: 0.3096 - val_loss: 4.3370 - val_accuracy: 0.1267\n",
      "Epoch 27/70\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 3.1075 - accuracy: 0.3213 - val_loss: 3.8892 - val_accuracy: 0.1733\n",
      "Epoch 28/70\n",
      "32/32 [==============================] - 7s 234ms/step - loss: 2.9716 - accuracy: 0.3359 - val_loss: 4.0676 - val_accuracy: 0.1591\n",
      "Epoch 29/70\n",
      "32/32 [==============================] - 7s 223ms/step - loss: 2.9298 - accuracy: 0.3294 - val_loss: 3.6384 - val_accuracy: 0.2038\n",
      "Epoch 30/70\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 2.7842 - accuracy: 0.3633 - val_loss: 3.9668 - val_accuracy: 0.1633\n",
      "Epoch 31/70\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 2.7600 - accuracy: 0.3848 - val_loss: 3.8839 - val_accuracy: 0.1777\n",
      "Epoch 32/70\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 2.7350 - accuracy: 0.3926 - val_loss: 3.6401 - val_accuracy: 0.2112\n",
      "Epoch 33/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 2.7263 - accuracy: 0.3945 - val_loss: 3.8152 - val_accuracy: 0.1932\n",
      "Epoch 34/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 2.7012 - accuracy: 0.4014 - val_loss: 3.6818 - val_accuracy: 0.1988\n",
      "Epoch 35/70\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 2.5735 - accuracy: 0.4111 - val_loss: 3.7719 - val_accuracy: 0.1920\n",
      "Epoch 36/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 2.5818 - accuracy: 0.4141 - val_loss: 3.5799 - val_accuracy: 0.2170\n",
      "Epoch 37/70\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 2.5999 - accuracy: 0.3936 - val_loss: 3.4248 - val_accuracy: 0.2434\n",
      "Epoch 38/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 2.5394 - accuracy: 0.4395 - val_loss: 3.9517 - val_accuracy: 0.1781\n",
      "Epoch 39/70\n",
      "32/32 [==============================] - 7s 230ms/step - loss: 2.4759 - accuracy: 0.4395 - val_loss: 3.8454 - val_accuracy: 0.1930\n",
      "Epoch 40/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 2.3299 - accuracy: 0.4570 - val_loss: 3.6180 - val_accuracy: 0.2156\n",
      "Epoch 41/70\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 2.3724 - accuracy: 0.4727 - val_loss: 3.3182 - val_accuracy: 0.2601\n",
      "Epoch 42/70\n",
      "32/32 [==============================] - 7s 233ms/step - loss: 2.4178 - accuracy: 0.4502 - val_loss: 3.4389 - val_accuracy: 0.2404\n",
      "Epoch 43/70\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 2.3123 - accuracy: 0.4590 - val_loss: 3.3706 - val_accuracy: 0.2507\n",
      "Epoch 44/70\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 2.1962 - accuracy: 0.5039 - val_loss: 4.1803 - val_accuracy: 0.1566\n",
      "Epoch 45/70\n",
      "32/32 [==============================] - 6s 205ms/step - loss: 2.2588 - accuracy: 0.4717 - val_loss: 3.2769 - val_accuracy: 0.2682\n",
      "Epoch 46/70\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 2.0975 - accuracy: 0.5166 - val_loss: 3.2819 - val_accuracy: 0.2682\n",
      "Epoch 47/70\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 2.0834 - accuracy: 0.5176 - val_loss: 3.3861 - val_accuracy: 0.2602\n",
      "Epoch 48/70\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 2.0951 - accuracy: 0.5176 - val_loss: 3.2646 - val_accuracy: 0.2761\n",
      "Epoch 49/70\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 2.1009 - accuracy: 0.5176 - val_loss: 3.4324 - val_accuracy: 0.2571\n",
      "Epoch 50/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 1.9315 - accuracy: 0.5439 - val_loss: 3.2881 - val_accuracy: 0.2745\n",
      "Epoch 51/70\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 1.9564 - accuracy: 0.5664 - val_loss: 3.8152 - val_accuracy: 0.2175\n",
      "Epoch 52/70\n",
      "32/32 [==============================] - 6s 202ms/step - loss: 2.0420 - accuracy: 0.5215 - val_loss: 3.3823 - val_accuracy: 0.2694\n",
      "Epoch 53/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.9006 - accuracy: 0.5654 - val_loss: 3.1662 - val_accuracy: 0.2895\n",
      "Epoch 54/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 1.8887 - accuracy: 0.5801 - val_loss: 3.1530 - val_accuracy: 0.2956\n",
      "Epoch 55/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.8647 - accuracy: 0.5586 - val_loss: 3.1593 - val_accuracy: 0.2963\n",
      "Epoch 56/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.9005 - accuracy: 0.5645 - val_loss: 3.2001 - val_accuracy: 0.2977\n",
      "Epoch 57/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.7644 - accuracy: 0.6055 - val_loss: 3.2851 - val_accuracy: 0.2726\n",
      "Epoch 58/70\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 1.7866 - accuracy: 0.5859 - val_loss: 3.4031 - val_accuracy: 0.2597\n",
      "Epoch 59/70\n",
      "32/32 [==============================] - 7s 224ms/step - loss: 1.7859 - accuracy: 0.6006 - val_loss: 3.1742 - val_accuracy: 0.2986\n",
      "Epoch 60/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.7408 - accuracy: 0.5986 - val_loss: 3.3675 - val_accuracy: 0.2694\n",
      "Epoch 61/70\n",
      "32/32 [==============================] - 7s 229ms/step - loss: 1.7652 - accuracy: 0.6016 - val_loss: 3.1525 - val_accuracy: 0.2942\n",
      "Epoch 62/70\n",
      "32/32 [==============================] - 7s 225ms/step - loss: 1.5814 - accuracy: 0.6438 - val_loss: 3.1723 - val_accuracy: 0.2951\n",
      "Epoch 63/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 1.5944 - accuracy: 0.6309 - val_loss: 3.1744 - val_accuracy: 0.2912\n",
      "Epoch 64/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 1.6706 - accuracy: 0.6113 - val_loss: 3.1732 - val_accuracy: 0.3018\n",
      "Epoch 65/70\n",
      "32/32 [==============================] - 7s 226ms/step - loss: 1.5459 - accuracy: 0.6357 - val_loss: 3.0499 - val_accuracy: 0.3178\n",
      "Epoch 66/70\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 1.5795 - accuracy: 0.6357 - val_loss: 3.1944 - val_accuracy: 0.2954\n",
      "Epoch 67/70\n",
      "32/32 [==============================] - 6s 198ms/step - loss: 1.5776 - accuracy: 0.6260 - val_loss: 3.0759 - val_accuracy: 0.3136\n",
      "Epoch 68/70\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 1.5416 - accuracy: 0.6562 - val_loss: 3.1151 - val_accuracy: 0.3146\n",
      "Epoch 69/70\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 1.5590 - accuracy: 0.6416 - val_loss: 3.2452 - val_accuracy: 0.2933\n",
      "Epoch 70/70\n",
      "32/32 [==============================] - 7s 213ms/step - loss: 1.4214 - accuracy: 0.6748 - val_loss: 2.9618 - val_accuracy: 0.3398\n",
      "for one training time taken: 503.34 seconds\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:36:21.694718: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.5100 - accuracy: 0.0186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:36:26.736650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 14s 418ms/step - loss: 5.5100 - accuracy: 0.0186 - val_loss: 5.8515 - val_accuracy: 0.0058\n",
      "Epoch 2/70\n",
      "32/32 [==============================] - 18s 557ms/step - loss: 5.2203 - accuracy: 0.0293 - val_loss: 5.6858 - val_accuracy: 0.0088\n",
      "Epoch 3/70\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 5.0797 - accuracy: 0.0410 - val_loss: 5.2984 - val_accuracy: 0.0213\n",
      "Epoch 4/70\n",
      "32/32 [==============================] - 14s 454ms/step - loss: 4.9771 - accuracy: 0.0439 - val_loss: 5.1967 - val_accuracy: 0.0267\n",
      "Epoch 5/70\n",
      "32/32 [==============================] - 13s 410ms/step - loss: 4.8632 - accuracy: 0.0527 - val_loss: 4.9729 - val_accuracy: 0.0380\n",
      "Epoch 6/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 4.7892 - accuracy: 0.0557 - val_loss: 4.8855 - val_accuracy: 0.0426\n",
      "Epoch 7/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 4.7572 - accuracy: 0.0596 - val_loss: 5.1307 - val_accuracy: 0.0287\n",
      "Epoch 8/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 4.7373 - accuracy: 0.0537 - val_loss: 4.9449 - val_accuracy: 0.0426\n",
      "Epoch 9/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 4.5247 - accuracy: 0.0811 - val_loss: 4.9377 - val_accuracy: 0.0487\n",
      "Epoch 10/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 4.4027 - accuracy: 0.0928 - val_loss: 4.5792 - val_accuracy: 0.0711\n",
      "Epoch 11/70\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 4.3315 - accuracy: 0.0996 - val_loss: 4.5916 - val_accuracy: 0.0642\n",
      "Epoch 12/70\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 4.1424 - accuracy: 0.1182 - val_loss: 4.8802 - val_accuracy: 0.0540\n",
      "Epoch 13/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 4.1289 - accuracy: 0.1436 - val_loss: 4.9288 - val_accuracy: 0.0524\n",
      "Epoch 14/70\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 3.9529 - accuracy: 0.1641 - val_loss: 4.4710 - val_accuracy: 0.0836\n",
      "Epoch 15/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 3.9861 - accuracy: 0.1572 - val_loss: 4.8188 - val_accuracy: 0.0639\n",
      "Epoch 16/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 3.7920 - accuracy: 0.2021 - val_loss: 4.4442 - val_accuracy: 0.0917\n",
      "Epoch 17/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 3.6653 - accuracy: 0.2080 - val_loss: 4.4007 - val_accuracy: 0.0989\n",
      "Epoch 18/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 3.7449 - accuracy: 0.1885 - val_loss: 4.3777 - val_accuracy: 0.1035\n",
      "Epoch 19/70\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 3.7087 - accuracy: 0.1963 - val_loss: 4.9317 - val_accuracy: 0.0544\n",
      "Epoch 20/70\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 3.5303 - accuracy: 0.2061 - val_loss: 4.0454 - val_accuracy: 0.1394\n",
      "Epoch 21/70\n",
      "32/32 [==============================] - 12s 385ms/step - loss: 3.3764 - accuracy: 0.2598 - val_loss: 4.0624 - val_accuracy: 0.1401\n",
      "Epoch 22/70\n",
      "32/32 [==============================] - 13s 417ms/step - loss: 3.3636 - accuracy: 0.2568 - val_loss: 4.0058 - val_accuracy: 0.1392\n",
      "Epoch 23/70\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 3.2011 - accuracy: 0.2881 - val_loss: 3.9177 - val_accuracy: 0.1566\n",
      "Epoch 24/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 3.1574 - accuracy: 0.2764 - val_loss: 3.8832 - val_accuracy: 0.1652\n",
      "Epoch 25/70\n",
      "32/32 [==============================] - 12s 392ms/step - loss: 3.1859 - accuracy: 0.2900 - val_loss: 3.7622 - val_accuracy: 0.1807\n",
      "Epoch 26/70\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 3.0008 - accuracy: 0.3252 - val_loss: 4.2985 - val_accuracy: 0.1188\n",
      "Epoch 27/70\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 2.9424 - accuracy: 0.3447 - val_loss: 3.7887 - val_accuracy: 0.1842\n",
      "Epoch 28/70\n",
      "32/32 [==============================] - 13s 404ms/step - loss: 2.8576 - accuracy: 0.3516 - val_loss: 3.8000 - val_accuracy: 0.1809\n",
      "Epoch 29/70\n",
      "32/32 [==============================] - 13s 400ms/step - loss: 2.7942 - accuracy: 0.3770 - val_loss: 3.5716 - val_accuracy: 0.2145\n",
      "Epoch 30/70\n",
      "32/32 [==============================] - 13s 399ms/step - loss: 2.9192 - accuracy: 0.3516 - val_loss: 3.5072 - val_accuracy: 0.2193\n",
      "Epoch 31/70\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 2.6815 - accuracy: 0.3809 - val_loss: 3.6187 - val_accuracy: 0.2094\n",
      "Epoch 32/70\n",
      "32/32 [==============================] - 13s 414ms/step - loss: 2.5745 - accuracy: 0.4062 - val_loss: 3.4043 - val_accuracy: 0.2354\n",
      "Epoch 33/70\n",
      "32/32 [==============================] - 11s 340ms/step - loss: 2.6370 - accuracy: 0.3857 - val_loss: 3.9775 - val_accuracy: 0.1679\n",
      "Epoch 34/70\n",
      "32/32 [==============================] - 10s 329ms/step - loss: 2.4812 - accuracy: 0.4365 - val_loss: 3.4717 - val_accuracy: 0.2367\n",
      "Epoch 35/70\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 2.3983 - accuracy: 0.4648 - val_loss: 3.5300 - val_accuracy: 0.2251\n",
      "Epoch 36/70\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 2.5216 - accuracy: 0.4306 - val_loss: 3.5453 - val_accuracy: 0.2184\n",
      "Epoch 37/70\n",
      "32/32 [==============================] - 10s 324ms/step - loss: 2.2711 - accuracy: 0.5098 - val_loss: 3.2681 - val_accuracy: 0.2645\n",
      "Epoch 38/70\n",
      "32/32 [==============================] - 12s 389ms/step - loss: 2.3723 - accuracy: 0.4551 - val_loss: 3.2965 - val_accuracy: 0.2625\n",
      "Epoch 39/70\n",
      "32/32 [==============================] - 13s 411ms/step - loss: 2.3190 - accuracy: 0.4697 - val_loss: 3.3197 - val_accuracy: 0.2692\n",
      "Epoch 40/70\n",
      "32/32 [==============================] - 12s 397ms/step - loss: 2.1451 - accuracy: 0.5000 - val_loss: 3.3300 - val_accuracy: 0.2627\n",
      "Epoch 41/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 2.2232 - accuracy: 0.4941 - val_loss: 3.3287 - val_accuracy: 0.2638\n",
      "Epoch 42/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 2.2006 - accuracy: 0.4834 - val_loss: 3.4251 - val_accuracy: 0.2574\n",
      "Epoch 43/70\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 2.0427 - accuracy: 0.5264 - val_loss: 3.2434 - val_accuracy: 0.2752\n",
      "Epoch 44/70\n",
      "32/32 [==============================] - 13s 402ms/step - loss: 1.9892 - accuracy: 0.5312 - val_loss: 3.3059 - val_accuracy: 0.2726\n",
      "Epoch 45/70\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 2.1113 - accuracy: 0.5293 - val_loss: 3.2132 - val_accuracy: 0.2844\n",
      "Epoch 46/70\n",
      "32/32 [==============================] - 13s 405ms/step - loss: 1.9663 - accuracy: 0.5469 - val_loss: 3.1570 - val_accuracy: 0.2877\n",
      "Epoch 47/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1.9284 - accuracy: 0.5410 - val_loss: 3.0839 - val_accuracy: 0.3027\n",
      "Epoch 48/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1.9719 - accuracy: 0.5439 - val_loss: 3.1714 - val_accuracy: 0.2895\n",
      "Epoch 49/70\n",
      "32/32 [==============================] - 13s 403ms/step - loss: 1.7175 - accuracy: 0.5898 - val_loss: 3.3472 - val_accuracy: 0.2662\n",
      "Epoch 50/70\n",
      "32/32 [==============================] - 13s 401ms/step - loss: 1.7511 - accuracy: 0.6006 - val_loss: 3.0553 - val_accuracy: 0.3074\n",
      "Epoch 51/70\n",
      "32/32 [==============================] - 13s 415ms/step - loss: 1.6943 - accuracy: 0.6191 - val_loss: 2.9380 - val_accuracy: 0.3401\n",
      "Epoch 52/70\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 1.7447 - accuracy: 0.6045 - val_loss: 3.2946 - val_accuracy: 0.2826\n",
      "Epoch 53/70\n",
      "32/32 [==============================] - 13s 408ms/step - loss: 1.7279 - accuracy: 0.6074 - val_loss: 2.9582 - val_accuracy: 0.3271\n",
      "Epoch 54/70\n",
      "32/32 [==============================] - 14s 432ms/step - loss: 1.6401 - accuracy: 0.6191 - val_loss: 3.0013 - val_accuracy: 0.3262\n",
      "Epoch 55/70\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 1.6213 - accuracy: 0.6221 - val_loss: 2.9265 - val_accuracy: 0.3393\n",
      "Epoch 56/70\n",
      "32/32 [==============================] - 13s 406ms/step - loss: 1.5560 - accuracy: 0.6475 - val_loss: 2.9258 - val_accuracy: 0.3438\n",
      "Epoch 57/70\n",
      "32/32 [==============================] - 15s 475ms/step - loss: 1.6360 - accuracy: 0.6182 - val_loss: 2.8540 - val_accuracy: 0.3431\n",
      "Epoch 58/70\n",
      "32/32 [==============================] - 12s 393ms/step - loss: 1.5249 - accuracy: 0.6465 - val_loss: 3.7932 - val_accuracy: 0.2182\n",
      "Epoch 59/70\n",
      "32/32 [==============================] - 11s 351ms/step - loss: 1.5384 - accuracy: 0.6582 - val_loss: 2.9633 - val_accuracy: 0.3301\n",
      "Epoch 60/70\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 1.5721 - accuracy: 0.6465 - val_loss: 2.9128 - val_accuracy: 0.3343\n",
      "Epoch 61/70\n",
      "32/32 [==============================] - 10s 323ms/step - loss: 1.4585 - accuracy: 0.6709 - val_loss: 3.0782 - val_accuracy: 0.3146\n",
      "Epoch 62/70\n",
      "32/32 [==============================] - 10s 325ms/step - loss: 1.5279 - accuracy: 0.6543 - val_loss: 2.9034 - val_accuracy: 0.3386\n",
      "Epoch 63/70\n",
      "32/32 [==============================] - 10s 322ms/step - loss: 1.3523 - accuracy: 0.6738 - val_loss: 3.1017 - val_accuracy: 0.3211\n",
      "Epoch 64/70\n",
      "32/32 [==============================] - 14s 445ms/step - loss: 1.4400 - accuracy: 0.6689 - val_loss: 2.8742 - val_accuracy: 0.3405\n",
      "Epoch 65/70\n",
      "32/32 [==============================] - 14s 456ms/step - loss: 1.2673 - accuracy: 0.7109 - val_loss: 2.7299 - val_accuracy: 0.3630\n",
      "Epoch 66/70\n",
      "32/32 [==============================] - 13s 418ms/step - loss: 1.3846 - accuracy: 0.6825 - val_loss: 2.9195 - val_accuracy: 0.3410\n",
      "Epoch 67/70\n",
      "32/32 [==============================] - 13s 423ms/step - loss: 1.2707 - accuracy: 0.7256 - val_loss: 3.0551 - val_accuracy: 0.3222\n",
      "Epoch 68/70\n",
      "32/32 [==============================] - 13s 412ms/step - loss: 1.4142 - accuracy: 0.6670 - val_loss: 2.8217 - val_accuracy: 0.3546\n",
      "Epoch 69/70\n",
      "32/32 [==============================] - 14s 443ms/step - loss: 1.2306 - accuracy: 0.7178 - val_loss: 2.8275 - val_accuracy: 0.3649\n",
      "Epoch 70/70\n",
      "32/32 [==============================] - 12s 387ms/step - loss: 1.2658 - accuracy: 0.7129 - val_loss: 2.9594 - val_accuracy: 0.3502\n",
      "for one training time taken: 889.33 seconds\n",
      "for all training time taken: 1392.67 seconds\n"
     ]
    }
   ],
   "source": [
    "model_and_best_hyperparameters([16,32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e05ca7b-7539-48ec-92a6-7a7f88d8a982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted list of average  epochs' values for accuracy   {1: 0.40475459737437114, 0: 0.37644513504845756}\n",
      "sorted list of max  epochs' values for accuracy   {1: 0.7255859375, 0: 0.6748046875}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted list of average  epochs' values for accuracy  \", max_or_min_avarage_val(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "# save_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67179992-f15d-432b-8e32-45e179ce34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'accuracy Sat May  6 11:19:23.txt'\n",
    "# l = read_list_from_file(file)\n",
    "# print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b49b6d-64b7-4aa9-b92e-f71dfeeb6f00",
   "metadata": {},
   "source": [
    "train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633a3702-1baf-4dab-a09c-3dee963376fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    ready_model = model(8,16,32,64)\n",
    "    call_back = ModelCheckpoint(f\"/home/jovyan/weights.hdf5\", monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    trained_model = ready_model.fit(training_set, steps_per_epoch = 32, epochs = 30, validation_data = test_set, callbacks = [call_back])\n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6d089bf-cdf6-466c-b982-050830bc5c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2995242242.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    trained_model = final_model()e\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# trained_model = final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd227c-d4d8-4b5d-80fe-3f7959fa5aa4",
   "metadata": {},
   "source": [
    "plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3b27-a90b-455a-93cb-59328ed8fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_many('accuracy', SAVED_MODEL_BEST_ACCURACY_RESULTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a59931-66c2-4806-a777-e4bfee1cad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if trained_model:\n",
    "    plot(trained_model.history['accuracy'], trained_model.history['loss'], trained_model.history['val_accuracy'], trained_model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8f3f1-649e-452d-922b-fa70c8ce7d92",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc123d2-9d89-44f2-989e-5d4c4d4bedc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict_model = Sequential()\n",
    "# for layer in model.layers[:-1]:\n",
    "#     predict_model.add(layer)\n",
    "# predict_model.add(Dense(units=1, activation=None))\n",
    "# predict_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "# predict_model.summary()\n",
    "\n",
    "predict_model = model(8,16,32,64)\n",
    "predict_model.summary()\n",
    "predict_model.load_weights('weights.hdf5')#, skip_mismatch=True, by_name=True)\n",
    "\n",
    "# # Load weights and biases from model manually\n",
    "# for i in range(len(predict_model.layers) - 1):\n",
    "#     predict_model.layers[i].set_weights(model.layers[i].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0dd9f-d192-4a8a-83a3-a97d19effe0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, known_data_path, unknown_data_path):\n",
    "    known_data = get_image_and_transform(known_data_path)\n",
    "    unknown_data = get_image_and_transform(unknown_data_path)\n",
    "\n",
    "    known_data = model.predict(known_data)\n",
    "    unknown_data = model.predict(unknown_data)\n",
    "    distance = unknown_data - known_data\n",
    "\n",
    "    threshold = 0.018614814\n",
    "    return  distance[0][0] < threshold, distance[0][0]\n",
    "\n",
    "predict(predict_model, '/home/jovyan/12.jpg', '/home/jovyan/11.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed7301-057b-4f6a-9569-c220b9e72a18",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9c60-bc0c-4586-8fc2-4eb86d972c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes, examples1 = get_examples_and_classes(test_folder,1)\n",
    "classes, examples2 = get_examples_and_classes(test_folder,2)\n",
    "y_true = [i for i in range(len(classes))]\n",
    "y_predict_tensors = []\n",
    "y_predict_labels = []\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    predict_label, predict_tensor = predict(predict_model, examples1[i], examples2[i])\n",
    "    y_predict_tensors.append(predict_tensor)\n",
    "    y_predict_labels.append(predict_label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292a756-9bbe-4a08-8a58-9d30b170abb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_predict_labels, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71eed0-463d-4c6b-9b8e-baf435aa25ce",
   "metadata": {},
   "source": [
    "choose best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094515cc-bc73-4f5c-8a6b-195dc45eadd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.0001, 0.5, 1000)\n",
    "\n",
    "# Calculate F1 score for each threshold\n",
    "f1_scores = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_predict_tensors < threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "# Choose the threshold that maximizes F1 score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
