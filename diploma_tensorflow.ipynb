{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f04fbf-b900-48bd-a2c1-6ea2895b26af",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6553d77d-0de9-4d79-bede-db30eb32a546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:50:42.785723: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-07 09:50:43.228019: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-07 09:50:43.228688: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-07 09:50:45.866733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6865a-b923-4561-a319-242ed82b2ab4",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51392f27-7832-4cab-a3ea-0a7c755446af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_BEST_ACCURACY_RESULTS = []\n",
    "SAVED_MODEL_BEST_LOSS_RESULTS = []\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abb70308-5f4f-4e97-a783-ddce4318c798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    data = utils.load_img(data, color_mode='grayscale', target_size=(64, 64))\n",
    "    data = utils.img_to_array(data)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    data = data / 255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3393a6-e4e3-4d4d-9f97-6b82aa56a007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_examples_and_classes(dataset_dir, num):\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    examples = []\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        examples.append(os.path.join(class_dir, images[num]))\n",
    "\n",
    "    return classes, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa81b474-0966-492b-8f25-eba67ab5cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(accuracy, loss, val_accuracy, val_loss):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('epoch')\n",
    "\n",
    "    ax1.set_ylabel('total loss')\n",
    "    ax1.plot(loss,color='tab:red')\n",
    "    ax1.plot( val_loss, color='tab:brown')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('accuracy')  \n",
    "    ax2.plot( accuracy, color='tab:blue')\n",
    "    ax2.plot( val_accuracy, color='tab:green')\n",
    "    ax2.tick_params(axis='y')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a71d1655-70cd-419b-b7cb-eff7a5a542c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_many(title='title', data=[]):\n",
    "    for i,o in enumerate(data):\n",
    "        plt.figure(i)\n",
    "        plt.plot([i for i in range(EPOCHS)],o, label=title)\n",
    "        plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab19927f-1208-4bfd-a329-933b6a21a2d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def max_or_min_avarage_val(list_of_data, accuracy=True):\n",
    "    dict_all_l = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        dict_all_l[i] = sum(o)/len(o)\n",
    "    if accuracy:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1], reverse=True))\n",
    "    else:\n",
    "        return dict(sorted(dict_all_l.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253f7b60-36bb-494f-9a81-078cc84b280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lists():\n",
    "    t = time.ctime(time.time())[:-5]\n",
    "    with open(f'accuracy {t}.txt', 'w') as f:\n",
    "        for item in SAVED_MODEL_BEST_ACCURACY_RESULTS:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    # with open(f'loss {t}.txt', 'w') as f:\n",
    "    #     for item in SAVED_MODEL_BEST_LOSS_RESULTS:\n",
    "    #         f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d59b4e0-8d86-4f58-a171-392fe5498f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filename):\n",
    "    lst = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            if line in ('', ' ','\\n'):\n",
    "                break\n",
    "            line = line[1:-2].split(', ')\n",
    "            lst.append([float(i.strip()) for i in line])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d9c0e79-cdeb-4c1a-9cfb-ec1fcd518589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_best_res(list_of_data):\n",
    "    max_val = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        max_val[i] = max(o)\n",
    "    return dict(sorted(max_val.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198520c-7008-4b6c-b7dd-bc94f7fc2f08",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7138b14b-26ee-4297-9c9b-2c552d9d6c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22734 images belonging to 164 classes.\n",
      "Found 5682 images belonging to 164 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_folder = \"/home/jovyan/dataset/dataset2/train\"\n",
    "test_folder = \"/home/jovyan/dataset/dataset2/test\"\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_folder,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder,\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            color_mode='grayscale')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f1f8-a05a-47b6-8962-711522d51998",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2d5c7a-7d38-463b-ac3e-19033eaef6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 31, 31, 8)        32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 8)         584       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 15, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 8)         264       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 7, 7, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 7, 7, 8)           264       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 3, 3, 8)          32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 72)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               37376     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 164)               84132     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,828\n",
      "Trainable params: 122,764\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model(in_1=8, in_2=8, in_3=8, in_4=8):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=in_1,kernel_size=3, strides=(1,1), input_shape=(64,64,1), padding='valid', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Conv2D(filters=in_2,kernel_size=3, strides=1, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=in_3,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=in_4,kernel_size=2, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(Dense(units = 512 , activation = 'tanh'))\n",
    "    model.add(Dense(units = 164 , activation = 'softmax'))\n",
    "\n",
    "    model.compile( optimizer = 'Adam', loss = 'categorical_crossentropy',metrics = ['accuracy']) # optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "    return model\n",
    "summary_example = model()\n",
    "summary_example.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf6c4-bed3-4b6f-92bd-9a2e9c16403a",
   "metadata": {},
   "source": [
    "choose best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "820b32f0-c987-41b1-bf6a-f268b1675ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_and_best_hyperparameters():\n",
    "    nums = [ 8,16, 32]\n",
    "    start_time1 = time.time()\n",
    "    for i in nums:        \n",
    "        start_time2 = time.time()\n",
    "        \n",
    "        ready_model = model(i,i*2,i*3, i*4)        # change order \n",
    "        trained_model = ready_model.fit(training_set, steps_per_epoch = 32, epochs = EPOCHS, validation_data = test_set)\n",
    "        \n",
    "        end_time2 = time.time()\n",
    "        print(\"for one training time taken: {:.2f} seconds\".format(end_time2 - start_time2))\n",
    "        \n",
    "        accuracy = trained_model.history['accuracy']\n",
    "        loss = trained_model.history['loss']\n",
    "\n",
    "        SAVED_MODEL_BEST_ACCURACY_RESULTS.append(accuracy)\n",
    "        SAVED_MODEL_BEST_LOSS_RESULTS.append(loss)\n",
    "        \n",
    "    end_time1 = time.time()\n",
    "    print(\"for all training time taken: {:.2f} seconds\".format(end_time1 - start_time1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa15b49-da5a-4cbb-bf6a-0fadef1326ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:50:50.925031: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.2694 - accuracy: 0.0127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:50:55.503063: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 250ms/step - loss: 5.2694 - accuracy: 0.0127 - val_loss: 5.1244 - val_accuracy: 0.0104\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 7s 237ms/step - loss: 5.0617 - accuracy: 0.0332 - val_loss: 5.2351 - val_accuracy: 0.0106\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 4.9783 - accuracy: 0.0229 - val_loss: 5.3895 - val_accuracy: 0.0097\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 7s 228ms/step - loss: 4.9049 - accuracy: 0.0322 - val_loss: 5.4312 - val_accuracy: 0.0088\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 8s 259ms/step - loss: 4.8412 - accuracy: 0.0342 - val_loss: 5.3977 - val_accuracy: 0.0107\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 4.7489 - accuracy: 0.0420 - val_loss: 5.6216 - val_accuracy: 0.0056\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 8s 246ms/step - loss: 4.6628 - accuracy: 0.0557 - val_loss: 5.5299 - val_accuracy: 0.0081\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 4.6305 - accuracy: 0.0547 - val_loss: 5.5097 - val_accuracy: 0.0118\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 7s 227ms/step - loss: 4.5809 - accuracy: 0.0596 - val_loss: 5.3438 - val_accuracy: 0.0137\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 5s 166ms/step - loss: 4.5540 - accuracy: 0.0684 - val_loss: 5.2647 - val_accuracy: 0.0183\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 5s 168ms/step - loss: 4.4922 - accuracy: 0.0625 - val_loss: 5.1960 - val_accuracy: 0.0208\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 8s 250ms/step - loss: 4.3580 - accuracy: 0.0967 - val_loss: 5.0451 - val_accuracy: 0.0271\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 7s 235ms/step - loss: 4.3353 - accuracy: 0.1016 - val_loss: 5.1158 - val_accuracy: 0.0283\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 7s 210ms/step - loss: 4.3391 - accuracy: 0.0859 - val_loss: 5.0350 - val_accuracy: 0.0370\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 7s 215ms/step - loss: 4.2625 - accuracy: 0.1006 - val_loss: 4.8943 - val_accuracy: 0.0421\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 5s 174ms/step - loss: 4.2799 - accuracy: 0.0898 - val_loss: 4.7360 - val_accuracy: 0.0519\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 4.2023 - accuracy: 0.1035 - val_loss: 4.9839 - val_accuracy: 0.0345\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 4s 143ms/step - loss: 4.1467 - accuracy: 0.1143 - val_loss: 4.8770 - val_accuracy: 0.0540\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 5s 174ms/step - loss: 4.0741 - accuracy: 0.1113 - val_loss: 4.5050 - val_accuracy: 0.0679\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 4.0890 - accuracy: 0.1104 - val_loss: 4.5233 - val_accuracy: 0.0685\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 4.0157 - accuracy: 0.1172 - val_loss: 4.3095 - val_accuracy: 0.0912\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 4.0226 - accuracy: 0.1302 - val_loss: 4.1036 - val_accuracy: 0.1139\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 7s 208ms/step - loss: 3.9532 - accuracy: 0.1484 - val_loss: 4.5900 - val_accuracy: 0.0815\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 3.9032 - accuracy: 0.1504 - val_loss: 4.7147 - val_accuracy: 0.0671\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 3.8882 - accuracy: 0.1543 - val_loss: 4.4258 - val_accuracy: 0.1030\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 3.8025 - accuracy: 0.1416 - val_loss: 4.6342 - val_accuracy: 0.0887\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 6s 207ms/step - loss: 3.8637 - accuracy: 0.1533 - val_loss: 4.7155 - val_accuracy: 0.0834\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 6s 203ms/step - loss: 3.8972 - accuracy: 0.1533 - val_loss: 4.0560 - val_accuracy: 0.1329\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 3.8138 - accuracy: 0.1631 - val_loss: 4.1798 - val_accuracy: 0.1191\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 3.7078 - accuracy: 0.1719 - val_loss: 4.9531 - val_accuracy: 0.0697\n",
      "for one training time taken: 198.51 seconds\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:54:09.177276: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.3198 - accuracy: 0.0137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:54:13.875271: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 10s 274ms/step - loss: 5.3198 - accuracy: 0.0137 - val_loss: 5.1359 - val_accuracy: 0.0070\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 10s 307ms/step - loss: 5.1723 - accuracy: 0.0254 - val_loss: 5.3032 - val_accuracy: 0.0106\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 10s 314ms/step - loss: 5.0532 - accuracy: 0.0273 - val_loss: 5.5494 - val_accuracy: 0.0106\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 9s 279ms/step - loss: 4.9819 - accuracy: 0.0361 - val_loss: 5.5360 - val_accuracy: 0.0106\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 4.8939 - accuracy: 0.0488 - val_loss: 5.6502 - val_accuracy: 0.0056\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 4.8508 - accuracy: 0.0342 - val_loss: 5.6278 - val_accuracy: 0.0063\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 9s 292ms/step - loss: 4.7409 - accuracy: 0.0469 - val_loss: 5.5190 - val_accuracy: 0.0088\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 10s 315ms/step - loss: 4.8200 - accuracy: 0.0479 - val_loss: 5.7455 - val_accuracy: 0.0106\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 9s 298ms/step - loss: 4.6185 - accuracy: 0.0713 - val_loss: 5.6141 - val_accuracy: 0.0160\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 8s 256ms/step - loss: 4.6302 - accuracy: 0.0566 - val_loss: 5.3976 - val_accuracy: 0.0121\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 8s 261ms/step - loss: 4.5679 - accuracy: 0.0771 - val_loss: 5.4301 - val_accuracy: 0.0111\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 9s 295ms/step - loss: 4.4765 - accuracy: 0.0791 - val_loss: 5.1133 - val_accuracy: 0.0229\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 9s 273ms/step - loss: 4.3474 - accuracy: 0.1035 - val_loss: 5.0100 - val_accuracy: 0.0313\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 9s 293ms/step - loss: 4.3088 - accuracy: 0.0957 - val_loss: 4.6115 - val_accuracy: 0.0700\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 9s 283ms/step - loss: 4.2148 - accuracy: 0.1162 - val_loss: 4.6064 - val_accuracy: 0.0669\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 4.1629 - accuracy: 0.1084 - val_loss: 4.4090 - val_accuracy: 0.0778\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 10s 307ms/step - loss: 4.2888 - accuracy: 0.0938 - val_loss: 4.4149 - val_accuracy: 0.0838\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 10s 308ms/step - loss: 4.1928 - accuracy: 0.1299 - val_loss: 4.4550 - val_accuracy: 0.0832\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 10s 310ms/step - loss: 4.0681 - accuracy: 0.1279 - val_loss: 4.4181 - val_accuracy: 0.0889\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 10s 304ms/step - loss: 4.0114 - accuracy: 0.1484 - val_loss: 4.8498 - val_accuracy: 0.0707\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 9s 297ms/step - loss: 3.9717 - accuracy: 0.1562 - val_loss: 4.8258 - val_accuracy: 0.0660\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 8s 267ms/step - loss: 4.0692 - accuracy: 0.1299 - val_loss: 4.2449 - val_accuracy: 0.1230\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 8s 254ms/step - loss: 3.8973 - accuracy: 0.1631 - val_loss: 3.9601 - val_accuracy: 0.1619\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 8s 255ms/step - loss: 3.8697 - accuracy: 0.1650 - val_loss: 3.9047 - val_accuracy: 0.1616\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 8s 243ms/step - loss: 3.9040 - accuracy: 0.1553 - val_loss: 3.9192 - val_accuracy: 0.1603\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 7s 238ms/step - loss: 3.8016 - accuracy: 0.1729 - val_loss: 3.9130 - val_accuracy: 0.1543\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 3.8331 - accuracy: 0.1719 - val_loss: 3.9684 - val_accuracy: 0.1480\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.7776 - accuracy: 0.1738 - val_loss: 3.9343 - val_accuracy: 0.1528\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 8s 245ms/step - loss: 3.6067 - accuracy: 0.2090 - val_loss: 3.7811 - val_accuracy: 0.1751\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 8s 242ms/step - loss: 3.6159 - accuracy: 0.1973 - val_loss: 3.8083 - val_accuracy: 0.1705\n",
      "for one training time taken: 265.07 seconds\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:58:34.274643: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - ETA: 0s - loss: 5.4012 - accuracy: 0.0127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-07 09:58:40.615621: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 15s 425ms/step - loss: 5.4012 - accuracy: 0.0127 - val_loss: 5.2769 - val_accuracy: 0.0072\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 12s 385ms/step - loss: 5.3236 - accuracy: 0.0215 - val_loss: 5.5452 - val_accuracy: 0.0072\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 12s 368ms/step - loss: 5.1798 - accuracy: 0.0254 - val_loss: 5.6831 - val_accuracy: 0.0065\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 11s 362ms/step - loss: 5.0427 - accuracy: 0.0322 - val_loss: 5.6128 - val_accuracy: 0.0095\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 12s 381ms/step - loss: 5.0521 - accuracy: 0.0273 - val_loss: 5.9568 - val_accuracy: 0.0106\n",
      "Epoch 6/30\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 4.9439 - accuracy: 0.0527 - val_loss: 5.9855 - val_accuracy: 0.0056\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 13s 420ms/step - loss: 4.8467 - accuracy: 0.0557 - val_loss: 5.8414 - val_accuracy: 0.0072\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 13s 427ms/step - loss: 4.7925 - accuracy: 0.0459 - val_loss: 6.1884 - val_accuracy: 0.0044\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 14s 431ms/step - loss: 4.7584 - accuracy: 0.0645 - val_loss: 5.7344 - val_accuracy: 0.0077\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 14s 437ms/step - loss: 4.7276 - accuracy: 0.0537 - val_loss: 5.5826 - val_accuracy: 0.0081\n",
      "Epoch 11/30\n",
      "32/32 [==============================] - 15s 467ms/step - loss: 4.5937 - accuracy: 0.0684 - val_loss: 5.6057 - val_accuracy: 0.0093\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 14s 457ms/step - loss: 4.5169 - accuracy: 0.0918 - val_loss: 5.4629 - val_accuracy: 0.0153\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 14s 461ms/step - loss: 4.4319 - accuracy: 0.0840 - val_loss: 5.6704 - val_accuracy: 0.0141\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 12s 390ms/step - loss: 4.3876 - accuracy: 0.0918 - val_loss: 5.4279 - val_accuracy: 0.0172\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 12s 391ms/step - loss: 4.4035 - accuracy: 0.0889 - val_loss: 5.1349 - val_accuracy: 0.0225\n",
      "Epoch 16/30\n",
      "32/32 [==============================] - 11s 335ms/step - loss: 4.3394 - accuracy: 0.0986 - val_loss: 4.8697 - val_accuracy: 0.0414\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 11s 346ms/step - loss: 4.2467 - accuracy: 0.1104 - val_loss: 4.9554 - val_accuracy: 0.0366\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 16s 505ms/step - loss: 4.1657 - accuracy: 0.1182 - val_loss: 4.7662 - val_accuracy: 0.0605\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 13s 409ms/step - loss: 4.1881 - accuracy: 0.1152 - val_loss: 4.6283 - val_accuracy: 0.0704\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 12s 391ms/step - loss: 4.1943 - accuracy: 0.1182 - val_loss: 5.2706 - val_accuracy: 0.0371\n",
      "Epoch 21/30\n",
      "32/32 [==============================] - 11s 338ms/step - loss: 4.0618 - accuracy: 0.1252 - val_loss: 4.5307 - val_accuracy: 0.0804\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 9s 298ms/step - loss: 4.0329 - accuracy: 0.1309 - val_loss: 4.2267 - val_accuracy: 0.1114\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 9s 297ms/step - loss: 3.9612 - accuracy: 0.1592 - val_loss: 4.2157 - val_accuracy: 0.1142\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 9s 297ms/step - loss: 3.8370 - accuracy: 0.1982 - val_loss: 4.4567 - val_accuracy: 0.0973\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 3.9681 - accuracy: 0.1611 - val_loss: 4.0077 - val_accuracy: 0.1447\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 9s 298ms/step - loss: 3.7925 - accuracy: 0.1768 - val_loss: 4.1674 - val_accuracy: 0.1169\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 9s 299ms/step - loss: 3.8374 - accuracy: 0.1797 - val_loss: 4.0018 - val_accuracy: 0.1478\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 9s 296ms/step - loss: 3.6778 - accuracy: 0.1924 - val_loss: 4.1632 - val_accuracy: 0.1218\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 9s 298ms/step - loss: 3.5674 - accuracy: 0.2207 - val_loss: 4.0365 - val_accuracy: 0.1345\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 9s 294ms/step - loss: 3.6234 - accuracy: 0.1992 - val_loss: 3.6347 - val_accuracy: 0.1968\n",
      "for one training time taken: 356.37 seconds\n",
      "for all training time taken: 819.95 seconds\n"
     ]
    }
   ],
   "source": [
    "model_and_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e05ca7b-7539-48ec-92a6-7a7f88d8a982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted list of average  epochs' values for accuracy   {1: 0.10608723958333334, 2: 0.10401218980550767, 0: 0.09585792527844508}\n",
      "sorted list of max  epochs' values for accuracy   {2: 0.220703125, 1: 0.208984375, 0: 0.171875}\n"
     ]
    }
   ],
   "source": [
    "print(\"sorted list of average  epochs' values for accuracy  \", max_or_min_avarage_val(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "save_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67179992-f15d-432b-8e32-45e179ce34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = 'accuracy Sat May  6 11:19:23.txt'\n",
    "# l = read_list_from_file(file)\n",
    "# print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b49b6d-64b7-4aa9-b92e-f71dfeeb6f00",
   "metadata": {},
   "source": [
    "train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "633a3702-1baf-4dab-a09c-3dee963376fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    ready_model = model(8,16,64)\n",
    "    call_back = ModelCheckpoint(f\"/home/jovyan/weights.hdf5\", monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    trained_model = model.fit(training_set, steps_per_epoch = 32, epochs = 30, validation_data = test_set, callbacks = [call_back])\n",
    "    return trained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6d089bf-cdf6-466c-b982-050830bc5c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_model = final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd227c-d4d8-4b5d-80fe-3f7959fa5aa4",
   "metadata": {},
   "source": [
    "plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa9d3b27-a90b-455a-93cb-59328ed8fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_many('accuracy', SAVED_MODEL_BEST_ACCURACY_RESULTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40a59931-66c2-4806-a777-e4bfee1cad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtrained_model\u001b[49m:\n\u001b[1;32m      2\u001b[0m     plot(trained_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], trained_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], trained_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], trained_model\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"
     ]
    }
   ],
   "source": [
    "if trained_model:\n",
    "    plot(trained_model.history['accuracy'], trained_model.history['loss'], trained_model.history['val_accuracy'], trained_model.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8f3f1-649e-452d-922b-fa70c8ce7d92",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc123d2-9d89-44f2-989e-5d4c4d4bedc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_model = Sequential()\n",
    "for layer in model.layers[:-1]:\n",
    "    predict_model.add(layer)\n",
    "predict_model.add(Dense(units=1, activation=None))\n",
    "predict_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "predict_model.summary()\n",
    "\n",
    "\n",
    "predict_model.load_weights('weights.hdf5', skip_mismatch=True, by_name=True)\n",
    "\n",
    "# # Load weights and biases from model manually\n",
    "# for i in range(len(predict_model.layers) - 1):\n",
    "#     predict_model.layers[i].set_weights(model.layers[i].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0dd9f-d192-4a8a-83a3-a97d19effe0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, known_data_path, unknown_data_path):\n",
    "    known_data = transform(known_data_path)\n",
    "    unknown_data = transform(unknown_data_path)\n",
    "\n",
    "    known_data = model.predict(known_data)\n",
    "    unknown_data = model.predict(unknown_data)\n",
    "    distance = unknown_data - known_data\n",
    "\n",
    "    threshold = 0.018614814\n",
    "    return  distance[0][0] > threshold, distance[0][0]\n",
    "\n",
    "predict(predict_model, '/home/jovyan/11.jpg', '/home/jovyan/21.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ed7301-057b-4f6a-9569-c220b9e72a18",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9c60-bc0c-4586-8fc2-4eb86d972c87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes, examples1 = get_examples_and_classes(test_folder,1)\n",
    "classes, examples2 = get_examples_and_classes(test_folder,2)\n",
    "y_true = [i for i in range(len(classes))]\n",
    "y_predict_tensors = []\n",
    "y_predict_labels = []\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    predict_label, predict_tensor = predict(predict_model, examples1[i], examples2[i])\n",
    "    y_predict_tensors.append(predict_tensor)\n",
    "    y_predict_labels.append(predict_label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292a756-9bbe-4a08-8a58-9d30b170abb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_predict_labels, target_names=classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71eed0-463d-4c6b-9b8e-baf435aa25ce",
   "metadata": {},
   "source": [
    "choose best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094515cc-bc73-4f5c-8a6b-195dc45eadd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thresholds = np.linspace(0.0001, 0.5, 1000)\n",
    "\n",
    "# Calculate F1 score for each threshold\n",
    "f1_scores = []\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_predict_tensors < threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_true, y_pred, average='micro'))\n",
    "\n",
    "# Choose the threshold that maximizes F1 score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "best_threshold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
