{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f04fbf-b900-48bd-a2c1-6ea2895b26af",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553d77d-0de9-4d79-bede-db30eb32a546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import utils\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shutil\n",
    "import splitfolders\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad354b46-1656-4149-9cc9-023a02606d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !unzip /home/jovyan/dataset2/221.zip -d /home/jovyan/dataset2/\n",
    "\n",
    "#!rm -r /home/jovyan/dataset2/val\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6865a-b923-4561-a319-242ed82b2ab4",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51392f27-7832-4cab-a3ea-0a7c755446af",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_BEST_ACCURACY_RESULTS = []\n",
    "SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS = []\n",
    "SAVED_MODEL_BEST_ACCURACY_RESULTS2 = []\n",
    "SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS2 = []\n",
    "EPOCHS = 170 # try different # 170 for dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb70308-5f4f-4e97-a783-ddce4318c798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_and_transform(path):\n",
    "    data = utils.load_img(path, color_mode='grayscale', target_size=(50, 180))\n",
    "    data = utils.img_to_array(data)\n",
    "    data = np.expand_dims(data, axis=0)\n",
    "    # data = data / 255.0\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f1fcef-0994-4627-b40f-3acdbdddfdca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(dataset_dir): # build 2 datasets for training and testing\n",
    "    x_train, y_train = [], []\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        for image in images:\n",
    "            full_image_path = os.path.join(class_dir, image)\n",
    "            if 'ipynb_checkpoints' in full_image_path:\n",
    "                continue\n",
    "            x_train.append(get_image_and_transform(full_image_path))\n",
    "            y_train.append(i)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3393a6-e4e3-4d4d-9f97-6b82aa56a007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_examples_and_classes(dataset_dir, num): # return persons' names and persons' ears\n",
    "    classes = sorted(os.listdir(dataset_dir))\n",
    "    classes.remove('.ipynb_checkpoints') if '.ipynb_checkpoints' in classes else None\n",
    "    examples = []\n",
    "    for i in range(len(classes)):\n",
    "        class_dir = os.path.join(dataset_dir, classes[i])\n",
    "        images = os.listdir(class_dir)\n",
    "        examples.append(os.path.join(class_dir, images[num]))\n",
    "\n",
    "    return classes, examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa81b474-0966-492b-8f25-eba67ab5cfa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(accuracy, loss, val_accuracy, val_loss): # return schedule of accuracy and loss\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.set_xlabel('epoch')\n",
    "\n",
    "    ax1.set_ylabel('total loss')\n",
    "    ax1.plot(loss,color='tab:red')\n",
    "    ax1.plot( val_loss, color='tab:brown')\n",
    "    ax1.tick_params(axis='y')\n",
    "\n",
    "    ax2 = ax1.twinx()  \n",
    "    ax2.set_ylabel('accuracy')  \n",
    "    ax2.plot( accuracy, color='tab:blue')\n",
    "    ax2.plot( val_accuracy, color='tab:green')\n",
    "    ax2.tick_params(axis='y')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d1655-70cd-419b-b7cb-eff7a5a542c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_many(title='title', data=[]): # return schedules of accuracy\n",
    "    for i,o in enumerate(data):\n",
    "        plt.figure(i)\n",
    "        plt.plot([i for i in range(EPOCHS)],o, label=title)\n",
    "        plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f7b60-36bb-494f-9a81-078cc84b280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lists(): # save lists of accuracy and loss\n",
    "    t = time.ctime(time.time())[:-5]\n",
    "    with open(f'accuracy {t}.txt', 'w') as f:\n",
    "        for item in SAVED_MODEL_BEST_ACCURACY_RESULTS:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    with open(f'val_accuracy {t}.txt', 'w') as f:\n",
    "        for item in SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS:\n",
    "            f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59b4e0-8d86-4f58-a171-392fe5498f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list_from_file(filename): # read accuracy or loss data  from files\n",
    "    lst = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            if line in ('', ' ','\\n'):\n",
    "                break\n",
    "            line = line[1:-2].split(', ')\n",
    "            lst.append([float(i.strip()) for i in line])\n",
    "    return lst\n",
    "# file = 'accuracy Sat May  6 11:19:23.txt'\n",
    "# l = read_list_from_file(file)\n",
    "# print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c0e79-cdeb-4c1a-9cfb-ec1fcd518589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_best_res(list_of_data): # return max value in every list of accuracy\n",
    "    max_val = {}\n",
    "    for i, o in enumerate(list_of_data):\n",
    "        max_val[i] = max(o)\n",
    "    return dict(sorted(max_val.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72436a61-67e4-4a1f-8128-f22659e2288a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_new_dataset(path):\n",
    "    images = sorted(os.listdir(path))\n",
    "    for image in images:\n",
    "        if 'ipynb_checkpoints' in image:\n",
    "            continue\n",
    "        old_path = f'/home/jovyan/dataset2/221/{image}'\n",
    "        new_path = f\"/home/jovyan/dataset2/dataset2/{image[:3]}\"\n",
    "\n",
    "        if os.path.exists(new_path):\n",
    "            shutil.copyfile(old_path, new_path+'/'+image)\n",
    "        else:\n",
    "            os.mkdir(new_path)\n",
    "            shutil.copyfile(old_path, new_path+'/'+image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198520c-7008-4b6c-b7dd-bc94f7fc2f08",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed47a4-8c69-48d5-af81-e6d5f87955d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_folder = \"/home/jovyan/dataset1/dataset2/train\"\n",
    "test_folder = \"/home/jovyan/dataset1/dataset2/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11e76ff-fb8f-4479-ba39-262735c35cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_folder = \"/home/jovyan/dataset2/221\"\n",
    "# create_new_dataset(data_folder)\n",
    "# train_datagen = \"/home/jovyan/dataset2/dataset2\"\n",
    "# splitfolders.ratio(train_datagen, output=\"/home/jovyan/dataset2\", seed=1337, ratio=(.8, 0.1,0.1)) \n",
    "train_folder = \"/home/jovyan/dataset2/train\"\n",
    "test_folder = \"/home/jovyan/dataset2/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138b14b-26ee-4297-9c9b-2c552d9d6c53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)#, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_folder,\n",
    "                                                 target_size = (50, 180),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 color_mode='grayscale')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_folder,\n",
    "                                            target_size = (50, 180),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            color_mode='grayscale')\n",
    "\n",
    "\n",
    "\n",
    "# print(training_set.filepaths)\n",
    "# print(training_set.classes)\n",
    "# print(training_set.class_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0f1f8-a05a-47b6-8962-711522d51998",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2d5c7a-7d38-463b-ac3e-19033eaef6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(in_1=32, in_2=32, in_3=32, in_4=64, l2_weight=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=in_1,kernel_size=3, strides=1, input_shape=(50,180,1), padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=in_2,kernel_size=3, strides=1, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=in_3,kernel_size=3, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=in_4,kernel_size=3, strides=1, padding ='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 512 , activation = 'tanh')) # try delete\n",
    "    model.add(Dense(units = 222 , activation = 'softmax'))\n",
    "\n",
    "    model.compile( optimizer='Adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "summary_example = model()\n",
    "summary_example.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfdf6c4-bed3-4b6f-92bd-9a2e9c16403a",
   "metadata": {},
   "source": [
    "choose best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b32f0-c987-41b1-bf6a-f268b1675ce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_and_best_hyperparameters(nums):\n",
    "    start_time1 = time.time() \n",
    "    for i in nums:\n",
    "        start_time2 = time.time()\n",
    "        \n",
    "        ready_model = model(i,i*2,i*3, i*4)        # change order \n",
    "        trained_model = ready_model.fit(training_set, steps_per_epoch = len(training_set), epochs = EPOCHS,\n",
    "                                        validation_data = test_set, validation_steps=len(test_set))\n",
    "        \n",
    "        print(\"for one training time taken: {:.2f} seconds\".format(time.time() - start_time2)) # how much time one training take\n",
    "\n",
    "        SAVED_MODEL_BEST_ACCURACY_RESULTS.append(trained_model.history['accuracy'])\n",
    "        SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS.append(trained_model.history['val_accuracy'])\n",
    "        \n",
    "    return time.time() - start_time1 # how much time all training take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa15b49-da5a-4cbb-bf6a-0fadef1326ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_time = model_and_best_hyperparameters([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e05ca7b-7539-48ec-92a6-7a7f88d8a982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(SAVED_MODEL_BEST_ACCURACY_RESULTS))\n",
    "print(\"sorted list of max  epochs' values for val_accuracy  \", show_best_res(SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS))\n",
    "print('all training take {:.2f} minutes'.format(all_time/60))\n",
    "# save_lists()  #val accuracy 0.4634"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b49b6d-64b7-4aa9-b92e-f71dfeeb6f00",
   "metadata": {},
   "source": [
    "train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a3702-1baf-4dab-a09c-3dee963376fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def final_model():\n",
    "    ready_model = model(32,64,64,32)\n",
    "    call_back = ModelCheckpoint(f\"/home/jovyan/weights.hdf5\", monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')\n",
    "    trained_model = ready_model.fit(training_set, steps_per_epoch = len(training_set), epochs = EPOCHS,\n",
    "                                    validation_data = test_set, validation_steps=len(test_set), callbacks = [call_back])\n",
    "    \n",
    "    SAVED_MODEL_BEST_ACCURACY_RESULTS2.append(trained_model.history['accuracy'])\n",
    "    SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS2.append(trained_model.history['val_accuracy'])\n",
    "    return trained_model, ready_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d089bf-cdf6-466c-b982-050830bc5c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history, trained_model = final_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dd227c-d4d8-4b5d-80fe-3f7959fa5aa4",
   "metadata": {},
   "source": [
    "plot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d3b27-a90b-455a-93cb-59328ed8fb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_many('accuracy', SAVED_MODEL_BEST_ACCURACY_RESULTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a59931-66c2-4806-a777-e4bfee1cad8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if trained_model:\n",
    "    print(\"sorted list of max  epochs' values for accuracy  \", show_best_res(SAVED_MODEL_BEST_ACCURACY_RESULTS2))\n",
    "    print(\"sorted list of max  epochs' values for val_accuracy  \", show_best_res(SAVED_MODEL_BEST_VAL_ACCURACY_RESULTS2))\n",
    "    plot(history.history['accuracy'], history.history['loss'], history.history['val_accuracy'], history.history['val_loss'])\n",
    "    # save_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8f3f1-649e-452d-922b-fa70c8ce7d92",
   "metadata": {},
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc123d2-9d89-44f2-989e-5d4c4d4bedc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_model = Sequential()\n",
    "ready_model2 = model(32,64,64,32)\n",
    "for layer in ready_model2.layers[:-1]:\n",
    "    predict_model.add(layer)\n",
    "predict_model.add(Dense(units=1, activation=None))\n",
    "predict_model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "predict_model.summary()\n",
    "\n",
    "\n",
    "predict_model.load_weights('weights.hdf5', skip_mismatch=True, by_name=True)\n",
    "\n",
    "# # Load weights and biases from model manually\n",
    "# for i in range(len(predict_model.layers) - 1):\n",
    "#     predict_model.layers[i].set_weights(model.layers[i].get_weights())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0dd9f-d192-4a8a-83a3-a97d19effe0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def distance_metric(x1, x2):\n",
    "    return tf.sqrt(tf.reduce_sum(tf.square(x1 - x2), axis=1))\n",
    "\n",
    "def predict(model, known_data_path, unknown_data_path):\n",
    "    known_data = get_image_and_transform(known_data_path)\n",
    "    unknown_data = get_image_and_transform(unknown_data_path)\n",
    "\n",
    "    known_data = model.predict(known_data)\n",
    "    unknown_data = model.predict(unknown_data)\n",
    "    distance = distance_metric(unknown_data, known_data)\n",
    "\n",
    "    threshold = 1\n",
    "    return  bool(distance < threshold), float(distance[0])\n",
    "\n",
    "predict(predict_model, '/home/jovyan/12.jpg', '/home/jovyan/11.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da71eed0-463d-4c6b-9b8e-baf435aa25ce",
   "metadata": {},
   "source": [
    "choose best threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ae146-cc0c-40fd-b5cb-74f26340f30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_threshold():\n",
    "    test_folder = \"/home/jovyan/dataset1/dataset2/test\"\n",
    "    classes, examples1 = get_examples_and_classes(test_folder,1) # every first image\n",
    "    classes, examples2 = get_examples_and_classes(test_folder,2) #every second image\n",
    "    examples3 = examples2[:len(examples2)//2]\n",
    "    examples3 += examples2[len(examples2)//2::-1] # second part of list is reversed second part of examples2 list\n",
    "    colors = ['blue' for i in range(len(examples2)//2)] + ['red' for i in range(len(examples2)//2)]\n",
    "    y_predict_tensors = []\n",
    "    y_predict_labels = []\n",
    "    del examples2\n",
    "\n",
    "\n",
    "    for i in range(len(examples1)):  # try build histogram\n",
    "        predict_label, predict_tensor = predict(predict_model, examples1[i], examples3[i])\n",
    "        y_predict_tensors.append(predict_tensor) # distance list\n",
    "        y_predict_labels.append(int(predict_label)) # bool list\n",
    "        \n",
    "    return y_predict_tensors, y_predict_labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ef4a6-f0e3-48f9-a918-dac776b1266a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_predict_tensors, y_predict_labels, colors = find_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09dac5f-a53b-41b2-b3b1-540f062450c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_predict_tensors, y_predict_labels, c=colors)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
